{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Audio to Text using Hugging Face Transformers\n",
                "This notebook demonstrates how to use the `transformers` library to convert audio to text using the OpenAI Whisper model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install necessary libraries if not present\n",
                "%pip install transformers torch torchaudio librosa"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "import torch\n",
                "\n",
                "# Check for GPU\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the ASR pipeline\n",
                "# We use 'openai/whisper-small' for a good balance of speed and accuracy\n",
                "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\", device=device)\n",
                "print(\"Model loaded successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Transcribe a sample audio file\n",
                "\n",
                "def transcribe_audio(file_path):\n",
                "    try:\n",
                "        # The pipeline handles loading and resampling automatically\n",
                "        result = transcriber(file_path)\n",
                "        return result[\"text\"]\n",
                "    except Exception as e:\n",
                "        return f\"Error: {e}\"\n",
                "\n",
                "# User File\n",
                "AUDIO_FILENAME = r\"C:\\Users\\HP\\Downloads\\WhatsApp Audio 2026-01-06 at 5.19.54 PM.mp4\"\n",
                "\n",
                "print(f\"Processing {AUDIO_FILENAME}...\")\n",
                "text = transcribe_audio(AUDIO_FILENAME)\n",
                "print(\"\\n--- Transcription ---\\n\")\n",
                "print(text)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
